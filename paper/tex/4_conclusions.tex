%We realize that the scope of the experiments we carried out is limited. In this case formulating general conclusions is very risky, but the preliminary results are quite promising, therefore we would like to continue the work on active learning approach in the future.
\noindent The novel active learning strategy for neural network classifiers has been proposed, where to implement the forgetting mechanism, we employed the \emph{catastrophic forgetting} phenomenon. The results of the experimental evaluation of the proposed algorithm carried out on the basis of diverse benchmark datasets and a detailed comparison with the semi-supervised and fully supervised strategies prove the usefulness of the proposed methods and show that it can better allocate the labeling budget.% the classification model is really need to be updated.

In the near future we are going to:
\begin{itemize}
\item Develop the methods which will allow to control the speed of forgetting, especially adaptive forgetting is the desirable characteristic, i.e., possibility of changing the forgetting speed on the basis of concept drift appearance frequency and/or its severity.
\item Evaluating the proposed algorithm behavior for more type of concept drift and maybe employ concept drift detector to establish the chunk size, threshold and budget dynamically.
\item Applying the proposed approach to the classifier ensemble.
\end{itemize}