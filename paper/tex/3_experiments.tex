\subsection{Goals}
\label{subsec:exp:goals}
\noindent The main goal of conducted experimental evaluation was to verify the impact of \emph{given budget} and \emph{treshold} values on overall classification accuracy, measured for each processed chunk, with the aim to calibrate parameters in a way that (a) reduces usage of labels (b) without classification accuracy deterioration.

\subsection{Setup}
\label{subsec:exp:setup}

\subsubsection{Software environment}

\noindent Most of the research devoted to \emph{data streams} is currently conducted using the \textsc{moa} environment \cite{Bifet:2010}, implemented in the \emph{Java} programming language. It includes a collection of base classifiers, necessary experimental methods, measurement tools and, above all, data stream generators. Knowing a growing tendency to employ \emph{scikit-learn} library \cite{scikit-learn}, it was decided to use it in implementation of the method described in following paper. It is not widely used with data streams, however, the potentiality of such processing was confirmed by a short article with a \emph{proof-of-concept} available in the on-line \emph{scikit-learn} documentation\footnote{\url{http://scikit-learn.org/stable/modules/scaling_strategies.html}}. 

It was necessary to create a new experimental flow for processing streams, enhanced with a class used to control a learning process. Current state of \emph{scikit-learn} library allows to process data streams using classifiers having implemented the \emph{partial fit} method, nevertheless as we mentioned above, we would like to employ inbuilt forgetting mechanism used by neural networks, therefore we used the implementation of \emph{\textsc{mlp}} --- Multi-layer Perceptron classifier, optimizing the log-loss function using \textsc{lbfgs} (\emph{Limited memory Broyden–-Fletcher–-Goldfarb–-Shanno}) algorithm \cite{Mokhtari:2015}.

The implementation of the active approach described in this paper as well as the workflow of learning from data streams using the \emph{scikit-learn} library are part of the \emph{stream-learn} module being developed by our research team\footnote{\url{https://github.com/w4k2/stream-learn}}. Full code of experiments and presented examples, together with extended research results, can be found in the article repository\footnote{\url{https://github.com/w4k2/active_learning}}.

\subsection{Benchmark data streams}

\noindent The pool of analyzed data consist of \oldstylenums{12} streams:


\begin{itemize}
	\item Three real streams:
    \begin{itemize}
    \item \emph{covtypeNorm} dataset \cite{Frank:2010} includes the observations which may be used to classify the cover type of a forest on the basis of cartographic variables. It contains \oldstylenums{54} attributes and \oldstylenums{7} class labels. The appearance of the concept drift is a result of the changes in geographical condition.
\item \emph{clecNormNew} (electricity) dataset \cite{Harries:1999} includes the data which may be used to predict the rise or fall of the electricity price in New South Wales, Australia. It contains \oldstylenums{6} attributes and \oldstylenums{2} classes. Concept drift is caused by the changes in consumption habits, events, and seasons.
\item\emph{poker-lsn} (poker hand) dataset \cite{Frank:2010} includes the data which may be used to poker hands. It contains \oldstylenums{10} attributes and \oldstylenums{10} classes. Concept drift is caused by card changing at hand.
    \end{itemize}
	\item Nine computer generated streams:
    \begin{itemize}
    \item Two streams with concept drift (\emph{RBFBlips, RBFGradualRecurring}) and one without it (\emph{RBFNoDrift}) generated with \emph{Radial Basis Function},
	\item A stream with a sudden drift (\emph{LED}) and without it (\emph{LEDNoDrift}) generated with LED generator,
	\item Two streams with sudden drifts with different dynamics (\emph{SEASudden, SEASuddenFaster}) generated with \emph{Streaming Ensemble Algorithm}\cite{Street:ui},
	\item Two streams with gradual drifts with different dynamics (\emph{HyperplaneFaster, HyperplaneSlow}) made by \emph{Hyperplane} generator.
    \end{itemize}
\end{itemize}

All the synthetic streams were generated by the \textsc{moa} software.

\subsubsection{Error evaluation}

\noindent Every classifier uses a recent portion of data to train, but its evaluation (i.e., error estimation) is done on the following (unseen) data chunk. This type of performance evaluation is known as \emph{test and train} or \emph{block evaluation method} \cite{Bifet:2010}. 

All the experiments were conducted with \textsc{mlp} classifier with \oldstylenums{100} neurons in hidden layer, using chunks with size of \oldstylenums{500} samples, evaluating the learning procedure after each percent of processed patterns.

%\begin{figure}[!ht]
%	\begin{center}
%		\resizebox {.8\columnwidth} {!} {\input{figures/testtrain}}
%		\vspace{1em}
%		\caption{Idea of \emph{Test and Train} evaluation.}	
%		\label{fig:testtrain}
%	\end{center}
%\end{figure}

\subsection{Results}
\label{subsec:exp:results}
\noindent Experiments were conducted with \oldstylenums{12} streams with three strategies:

\begin{itemize}
	\item Measuring accuracy of incrementally training a model with all samples available in data stream.
	\item Measuring accuracy of incrementally trained model with randomized chunk subset, according to a given budget with five values in range \oldstylenums{10}---\oldstylenums{90}\%.
	\item Measuring accuracy of incrementally trained model with active learning approach described in Section 2 with five values in range \oldstylenums{10}---\oldstylenums{90}\% for both given budget and threshold.
\end{itemize}

Because conducted experiments produced many learning curves, only the part of them is included in the paper, but the detailed experimental results may be found in the article repository\footnote{\url{https://github.com/w4k2/active_learning}}.

Figure \ref{fig:budget_learning_curve} shows, with a blue line, a learning curve for three different budget values (\oldstylenums{30}\%, \oldstylenums{50}\%, and \oldstylenums{70}\%), while the black line is a curve for the classifier trained on the basis of all labeled examples (budget = \oldstylenums{100}\%).

\input{figures/budget_learning_curve}

Decreasing a given budget leads, similarly to increasing the chunk or reducing a structure, to reduce the dynamics of learning. Therefore, it can not be a sufficient practice to reduce the cost of labeling. To maintain the accuracy of learning on a smaller training set, it is necessary to select the appropriately reduced set of samples, which we try to achieve by the proposed active learning method.

For the same stream, Figure \ref{fig:treshold_learning_curve} shows, with a continuous red line, a learning curve for three different threshold values ($.1$, $.3$, and $.9$) with a fixed budget of \oldstylenums{70}\%. The black line is a curve for learning with all samples labeled, while the red dotted line is the percentage of samples used to train the model.

\input{figures/treshold_learning_curve}

As we can see, too restrictive value of the threshold ($t = .1$) reduces the dynamics of the learning curve similarly to a low budget. The case of overly lax threshold ($t = .9$) allows to obtain the correct learning curve, but it does not reduce the samples necessary for the labeling, so it is no different from using only the budget parameter. However, proper calibration of the threshold ($t = .3$) allows to obtain the optimal learning curve, gradually reducing the need for sample labeling while obtaining knowledge by the classifier.

Figure \ref{fig:result_plots} shows the learning curves for selected, best parameters of a given budget and threshold for all tested data streams (continuous red lines). The black line is a curve for learning with all samples labeled. The red dotted line is the percentage of samples which were labeled during the model training.

\input{figures/result_plots}

Table \ref{tab:results} presents a summary of the results obtained for the best combinations. It contains, for each data set, selected parameters, average accuracy for the model learned on the full and reduced stream, the difference between the accuracies and the percentage use of the stream.

\input{tables/accuracies}

\subsection{Analysis of the results}
\label{subsec:exp:analysis}

\noindent Most of the observations discussed around the Figures \ref{fig:budget_learning_curve} and \ref{fig:treshold_learning_curve} are confirmed by curves available in the Figure \ref{fig:result_plots}. We need to reject the \emph{elecNormNew} dataset, where even training with the fully labeled dataset led to a model with results similar to a random classifier.
%PAWEŁ CZY POWYŻEJ CHODZIŁO CI O RANDOM CLASSIFIER -CZY O TAKI, KTÓRY JEST FULL SUPERVISED
%ODP. Chodziło mi właśnie o klasyfikator losowy, a więc random classifier.
It is worth mentioning that Zliobaite \cite{Zliobaite:2013} observes the problem of testing data stream classifiers on autocorrelated data and that getting high accuracy, especially on the \emph{elecNormNew} dataset does not necessarily mean that the adaptation mechanism work well. 

In every dataset, after this exclusion, a tendency to consequently reducing the chunk usage is observed. In the case streams with many concept drifts (\emph{RBFGradualRecurring} and \emph{RBFBlips}) the reduction of label use is relatively small, but it is caused by a slow accumulation of knowledge of the selected classifier, where \oldstylenums{100} neurons in the hidden layer were not sufficient to achieve the maximum accuracy of classification before the next drift. We may also observe the intensive growth of the label demand, when a concept drift appears.

For data streams generated by \emph{Streaming Ensemble Algorithm}, the reduction of the accuracy is not observed. In the case of two sets of data (\emph{SEASudden} and \emph{HyperplaneSlow}), the appropriate combination of a given budget and threshold allows not only to preserve the dynamics of learning, but also to accelerate it.

Even in the case of data streams where the selected neural network structure was insufficient to achieve full discriminative power before occurrence of the next drift, it was possible to reduce the number of samples necessary for labeling by \oldstylenums{10}--\oldstylenums{20}\%. In the case of the remaining sets, a reduction of \oldstylenums{50}--\oldstylenums{90}\% was achieved, without a negative impact on the average quality of the classification.

\subsection{Lessons learned}
Let us summarize the research findings and observations that could be drawn from the experimental analysis:
\begin{itemize}
	\item Active learning approach may lead to a solution where a trained model keeps the classification accuracy of full-stream learning, with a slight reduction of used labels.
	\item There is no rule of correct setting the parameters related to a given budget and threshold, so it should be calibrated for a particular task.
	\item Active learning approach is able to detect a concept drift and react on it without negative impact on classification accuracy.
	\item Chunk usage decreases slowly in time, according to stabilization of a model on current concept.
	\item Acquiring the necessary knowledge by a model reduces the need for new samples.
	%PAWEŁ WYJAŚNIJ PONIŻSZE POJĘCIE KNOWLEDGE SATURATION
	%ODP. Przez nasycenie wiedzą miałem na myśli stopień uzyskania maksymalnej mocy dyskryminacyjnej. 
    \item A \emph{knowledge saturation} (degree of obtaining the maximum discriminative power) of a model can be successfully measured by \textsc{rfsd}.
    %PAWEŁ PONIŻSZA UWAGA JEST DOŚĆ POKRĘTNA, ZASTANÓW SIĘ< CZY JEJ NIE USUNĄĆ
    %ODP. Z przykładu z rysunku 5 wynikało początkowo, że być może wypadałoby całkowicie zrezygnować z budżetu, bo to przez próg najłatwiej kalibruje się aktywny klasyfikator. W niektórych przypadkach (właśnie tych dwóch) jednak widać, że połączenie obu ograniczeń czasami pozwala na polepszenie krzywej uczenia. Ale usunę uwagę, bo faktycznie nie do końca potrafię to wyjaśnić. 
	%\item The budget parameter is not unnecessary when using the threshold, because it can be seen that in some cases (HyperplaneSlow, SEASudden) and with a suitably matched threshold, it can even improve the learning curve in relation to the use of all patterns.
	\item Chunk reduction has a positive effect by increasing the learning frequency but extends the learning time itself.
    %PAWEŁ PONIŻSZE DWIE UWAGI PRZEISAŁEM - ZOBACZ, CZY WG CIEBIE JEST TERAZ OK, CZY COŚ  DODAĆ
    % ODP. Moim zdaniem jest teraz OK.
%	\item The greater the number of neurons, the higher accuracy decreases when the concept drifts.
%	\item Appropriate increase in the number of neurons allows the immunization of the model to accuracy decreases occurring at the incremental drift.
 \item The size of a neural network which is responsible for the concept memorization should be set carefully, for a given decision task, because on the one hand the smaller structure of the network the faster is its reaction to the concept drift, what is especially important in the case of sudden drift. Such fast model adaptation protect against the huge classification accuracy drop. On the other hand appropriate increasing of neural network size allows the immunization of the model to accuracy drop when the slow, incremental concept drift goes ahead. 
 	%PAWEŁ WYJAŚNIJ/ROZSZERZ PONIŻSZE.
 	%ODP. Chodzi mi właśnie o obserwację z rys 5, gdzie zmiejszenie przez budżet -- losowy podzbiór, spłaszcza krzywą uczenia. 
	\item Limitation of training set by just a given budget with random subset of samples causes a proportional reduction in the learning dynamics.
\end{itemize}

\label{subsec:exp:ll}